{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from nimosef.utils.stats import pairwise_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/media/jaume/DATA/Data/Test_NIMOSEF_Dataset\"\n",
    "splits_filename=f\"{data_path}/derivatives/manifests_nimosef/dataset_manifest.json\"\n",
    "\n",
    "mode=\"train\"\n",
    "results_folder = f\"{data_path}/derivatives/nimosef_results\"\n",
    "save_folder_results = os.path.join(results_folder, f\"results_{mode}_comparison\")\n",
    "os.makedirs(save_folder_results, exist_ok=True)\n",
    "\n",
    "# Metadata filename\n",
    "metadata_filename = os.path.join(data_path, \"derivatives\", \"metadata_participants_ALL.tsv\")\n",
    "df_metadata = pd.read_csv(metadata_filename, sep='\\t')\n",
    "df_metadata['Subject'] = df_metadata['Subject'].astype(str)\n",
    "df_metadata['bsa_img_2.0'] = df_metadata['bsa_img_2.0'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image metrics\n",
    "volumes_df_path = os.path.join(save_folder_results, 'volumes_imgs.parquet')\n",
    "df_volumes = pd.read_parquet(volumes_df_path)\n",
    "df_volumes[\"Subject\"] = df_volumes[\"Subject\"].astype(str)\n",
    "\n",
    "final_df_path = os.path.join(save_folder_results, 'connected_components.parquet')\n",
    "final_df = pd.read_parquet(final_df_path)\n",
    "\n",
    "dice_df_path = os.path.join(save_folder_results, 'dice_score.parquet')\n",
    "df_dice_final = pd.read_parquet(dice_df_path)\n",
    "\n",
    "label_map = {1.0: 'LV', 2.0: 'MYO', 3.0: 'RV'}\n",
    "final_df['label'] = final_df['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_all with df_metadata by using 'Subject' from df_all and the index of df_metadata\n",
    "df_all_merged = pd.merge(df_volumes, df_metadata[['bsa_img_2.0', 'Subject']], left_on=\"Subject\", right_on=\"Subject\", how=\"left\")\n",
    "\n",
    "# Optionally, rename the column for clarity\n",
    "df_all_merged.rename(columns={'bsa_img_2.0': 'BSA'}, inplace=True)\n",
    "\n",
    "# Compute the Volume_Index column as Volume divided by BSA\n",
    "df_all_merged['Volume_Index'] = df_all_merged['Volume'] / df_all_merged['BSA']\n",
    "\n",
    "# Display the first few rows to check the merge\n",
    "print(df_all_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Compute group-level statistics: mean and 95% confidence intervals (CI)\n",
    "# ---------------------------\n",
    "# Group the data by segmentation type, time, and class\n",
    "grouped = df_all_merged.groupby(['segmentation_type', 'Time', 'Class'])\n",
    "\n",
    "# Aggregate the data: mean, std, and count\n",
    "summary = grouped.agg(\n",
    "    mean_volume=('Volume', 'mean'),\n",
    "    std_volume=('Volume', 'std'),\n",
    "    count_volume=('Volume', 'count'),\n",
    "    mean_deriv=('Derivative', 'mean'),\n",
    "    std_deriv=('Derivative', 'std'),\n",
    "    count_deriv=('Derivative', 'count'),\n",
    "    mean_volume_index=('Volume_Index', 'mean'),\n",
    "    std_volume_index=('Volume_Index', 'std'),\n",
    "    count_volume_index=('Volume_Index', 'count'),\n",
    ").reset_index()\n",
    "\n",
    "# Compute the standard error and 95% CI (assuming normality, 1.96 * SE)\n",
    "summary['se_volume'] = summary['std_volume'] / np.sqrt(summary['count_volume'])\n",
    "summary['ci_volume'] = summary['se_volume'] * 1.96\n",
    "\n",
    "summary['se_deriv'] = summary['std_deriv'] / np.sqrt(summary['count_deriv'])\n",
    "summary['ci_deriv'] = summary['se_deriv'] * 1.96\n",
    "\n",
    "summary['se_volume_index'] = summary['std_volume_index'] / np.sqrt(summary['count_volume_index'])\n",
    "summary['ci_volume_index'] = summary['se_volume_index'] * 1.96\n",
    "\n",
    "# print(summary.head())\n",
    "classes = df_all_merged['Class'].unique()\n",
    "seg_types = df_all_merged['segmentation_type'].unique()\n",
    "\n",
    "# title_dict = {'gt':'CNN reference', 'pred_new': 'Ours', 'pred_base': 'Baseline'}\n",
    "title_dict = {'gt':'CNN reference', 'pred': 'Ours'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'summary' is the aggregated DataFrame from the previous code snippet\n",
    "# and 'classes' is defined (e.g., ['LV', 'Myo', 'RV']).\n",
    "# variable_to_plot = 'mean_volume'\n",
    "# ci_to_plot = 'ci_volume'\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"talk\", font_scale=1., \n",
    "                  rc={\"font.size\": 18, \"axes.titlesize\": 18, \"axes.labelsize\": 18,\n",
    "                      \"xtick.labelsize\": 18, \"ytick.labelsize\": 18})\n",
    "\n",
    "variable_to_plot = 'mean_volume_index'\n",
    "ci_to_plot = 'ci_volume_index'\n",
    "\n",
    "# Set up the figure with 3 horizontal subplots sharing the y-axis.\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# Loop through each segmentation type and plot the data\n",
    "for ax, seg in zip(axs, seg_types):\n",
    "    df_seg = summary[summary['segmentation_type'] == seg]\n",
    "    for cl in classes:\n",
    "        df_cl = df_seg[df_seg['Class'] == cl]\n",
    "\n",
    "        ax.plot(df_cl['Time'], df_cl[f'{variable_to_plot}'], label=f'{cl} Mean')\n",
    "        ax.fill_between(df_cl['Time'],\n",
    "                     df_cl[f'{variable_to_plot}'] - df_cl[f'{ci_to_plot}'],\n",
    "                     df_cl[f'{variable_to_plot}'] + df_cl[f'{ci_to_plot}'],\n",
    "                     alpha=0.3, label=f'{cl} 95% CI')\n",
    "    \n",
    "    ax.set_title(f'{title_dict[seg]}')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.grid(True)\n",
    "\n",
    "# Set the common y-axis label on the left subplot\n",
    "axs[0].set_ylabel('Volume Index [ml/m2]')\n",
    "\n",
    "# Create one common legend for all subplots\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(classes)*2, frameon=True)\n",
    "\n",
    "# Adjust layout to create space for the legend above the plots\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "save_filename = os.path.join(save_folder_results, 'volume_index.png')\n",
    "fig.savefig(save_filename, dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "save_filename = os.path.join(save_folder_results, 'volume_index.eps')\n",
    "fig.savefig(save_filename, format='eps', dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "save_filename = os.path.join(save_folder_results, 'volume_index.pdf')\n",
    "fig.savefig(save_filename, format='pdf', dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure with 3 horizontal subplots sharing the y-axis.\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(18, 6), sharey=True)\n",
    "# sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"talk\", font_scale=1., \n",
    "                  rc={\"font.size\": 18, \"axes.titlesize\": 18, \"axes.labelsize\": 18,\n",
    "                      \"xtick.labelsize\": 18, \"ytick.labelsize\": 18})\n",
    "\n",
    "# Loop through each segmentation type and plot the derivative data\n",
    "for ax, seg in zip(axs, seg_types):\n",
    "    df_seg = summary[summary['segmentation_type'] == seg]\n",
    "    for cl in classes:\n",
    "        df_cl = df_seg[df_seg['Class'] == cl]\n",
    "\n",
    "        ax.plot(df_cl['Time'], df_cl['mean_deriv'], marker='o', label=cl)\n",
    "        ax.fill_between(\n",
    "            df_cl['Time'],\n",
    "            df_cl['mean_deriv'] - df_cl['ci_deriv'],\n",
    "            df_cl['mean_deriv'] + df_cl['ci_deriv'],\n",
    "            alpha=0.3\n",
    "        )\n",
    "    ax.set_title(f'{title_dict[seg]}')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.grid(True)\n",
    "\n",
    "# Set a common y-axis label on the left subplot\n",
    "axs[0].set_ylabel('Derivative (Change in Volume)')\n",
    "\n",
    "# Create one common legend for all subplots\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(classes)*2, frameon=True)\n",
    "\n",
    "# Adjust layout to create space for the legend above the plots\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "save_filename = os.path.join(save_folder_results, 'volume_index_derivative.png')\n",
    "fig.savefig(save_filename, dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "save_filename = os.path.join(save_folder_results, 'volume_index_derivative.eps')\n",
    "fig.savefig(save_filename, format='eps', dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "save_filename = os.path.join(save_folder_results, 'volume_index_derivative.pdf')\n",
    "fig.savefig(save_filename, format='pdf', dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 1: Compute per‚Äêsubject measures for each subject, segmentation, and class ---\n",
    "# title_dict = {'gt':'CNN reference', 'pred_new': 'Ours', 'pred_base': 'Baseline'}\n",
    "# We choose the variable to analyze (for volume, use 'Volume_Index'; otherwise, use 'Volume')\n",
    "measure = 'Volume_Index'\n",
    "\n",
    "# Compute minimum and maximum volume per subject\n",
    "df_min_vol = df_all_merged.groupby(['Subject', 'segmentation_type', 'Class'])[measure].min().reset_index().rename(columns={measure: 'MinVolume'})\n",
    "df_max_vol = df_all_merged.groupby(['Subject', 'segmentation_type', 'Class'])[measure].max().reset_index().rename(columns={measure: 'MaxVolume'})\n",
    "\n",
    "# Compute EF = (Max - Min) / Max for each subject (merge min and max data)\n",
    "df_ef = pd.merge(df_min_vol, df_max_vol, on=['Subject', 'segmentation_type', 'Class'])\n",
    "df_ef['EF'] = (df_ef['MaxVolume'] - df_ef['MinVolume']) / df_ef['MaxVolume']\n",
    "df_ef['EF'] = df_ef['EF'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# Compute Stroke Volume (SV) as (MaxVolume - MinVolume)\n",
    "# Merge the min and max volume dataframes\n",
    "df_sv = pd.merge(df_min_vol, df_max_vol, on=['Subject', 'segmentation_type', 'Class'])\n",
    "df_sv['SV'] = df_sv['MaxVolume'] - df_sv['MinVolume']\n",
    "\n",
    "# For Derivative measures, assume df_all_merged has a 'Derivative' column.\n",
    "# Compute per-subject min and max derivative for each subject, segmentation, and class.\n",
    "df_deriv = (df_all_merged.groupby(['Subject', 'segmentation_type', 'Class'])['Derivative']\n",
    "                .apply(lambda x: np.abs(x).max())\n",
    "                .reset_index(name='MaxDeriv'))\n",
    "# df_max_deriv = df_all_merged.groupby(['Subject', 'segmentation_type', 'Class'])['Derivative'].max().reset_index().rename(columns={'Derivative': 'MaxDeriv'})\n",
    "# df_deriv = pd.merge(df_min_deriv, df_max_deriv, on=['Subject', 'segmentation_type', 'Class'])\n",
    "\n",
    "# --- STEP 2: Create Boxplots for each Measure ---\n",
    "\n",
    "# We will create boxplots for:\n",
    "# - Minimum Volume, Maximum Volume, Minimum Derivative, Maximum Derivative, and EF\n",
    "fig, axs = plt.subplots(1, 5, figsize=(25, 6), sharey=False)\n",
    "sns.boxplot(data=df_min_vol, x='segmentation_type', y='MinVolume', hue='Class', ax=axs[0])\n",
    "axs[0].set_title('ESVI')\n",
    "axs[0].set_xlabel('')\n",
    "axs[0].set_ylabel('')\n",
    "\n",
    "sns.boxplot(data=df_max_vol, x='segmentation_type', y='MaxVolume', hue='Class', ax=axs[1])\n",
    "axs[1].set_title('EDVI')\n",
    "axs[1].set_xlabel('')\n",
    "axs[1].set_ylabel('')\n",
    "# sns.boxplot(data=df_deriv, x='segmentation_type', y='MinDeriv', hue='Class', ax=axs[2])\n",
    "# axs[2].set_title('Min Derivative')\n",
    "sns.boxplot(data=df_sv, x='segmentation_type', y='SV', hue='Class', ax=axs[2])\n",
    "axs[2].set_title('SVI')\n",
    "axs[2].set_xlabel('')\n",
    "axs[2].set_ylabel('')\n",
    "\n",
    "sns.boxplot(data=df_deriv, x='segmentation_type', y='MaxDeriv', hue='Class', ax=axs[3])\n",
    "axs[3].set_title('Max Derivative')\n",
    "axs[3].set_xlabel('')\n",
    "axs[3].set_ylabel('')\n",
    "\n",
    "sns.boxplot(data=df_ef, x='segmentation_type', y='EF', hue='Class', ax=axs[4])\n",
    "axs[4].set_title('EF')\n",
    "axs[4].set_xlabel('')\n",
    "axs[4].set_ylabel('')\n",
    "\n",
    "# Loop over all axes to rename x-tick labels based on title_dict:\n",
    "for ax in axs:\n",
    "    new_labels = [title_dict.get(label.get_text(), label.get_text()) for label in ax.get_xticklabels()]\n",
    "    ax.set_xticklabels(new_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "save_filename = os.path.join(save_folder_results, 'group_comparisons.png')\n",
    "fig.savefig(save_filename, dpi=300, bbox_inches='tight', pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 3: Pairwise Comparisons Between Segmentation Groups ---\n",
    "# We define a helper function to perform paired tests (Wilcoxon signed-rank test)\n",
    "\n",
    "# Compute pairwise tests for each measure:\n",
    "df_pw_min_vol    = pairwise_comparisons(df_min_vol, 'MinVolume', group_col='segmentation_type', subject_col='Subject')\n",
    "df_pw_max_vol    = pairwise_comparisons(df_max_vol, 'MaxVolume', group_col='segmentation_type', subject_col='Subject')\n",
    "# df_pw_min_deriv  = pairwise_comparisons(df_deriv, 'MinDeriv', group_col='segmentation_type', subject_col='Subject')\n",
    "df_pw_sv  = pairwise_comparisons(df_sv, 'SV', group_col='segmentation_type', subject_col='Subject')\n",
    "df_pw_max_deriv  = pairwise_comparisons(df_deriv, 'MaxDeriv', group_col='segmentation_type', subject_col='Subject')\n",
    "df_pw_ef         = pairwise_comparisons(df_ef, 'EF', group_col='segmentation_type', subject_col='Subject')\n",
    "\n",
    "# Combine all pairwise results\n",
    "df_pairwise = pd.concat([df_pw_min_vol, df_pw_max_vol, df_pw_sv, df_pw_max_deriv, df_pw_ef], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\", font_scale=1.5, \n",
    "                  rc={\"font.size\": 18, \"axes.titlesize\": 18, \"axes.labelsize\": 18,\n",
    "                      \"xtick.labelsize\": 18, \"ytick.labelsize\": 18})\n",
    "\n",
    "\n",
    "# Define the order and renaming dictionary\n",
    "# order = ['gt', 'pred_base', 'pred_new']\n",
    "order = ['gt', 'pred']\n",
    "# title_dict = {'gt':'CNN reference', 'pred_new': 'Ours', 'pred_base': 'Baseline'}\n",
    "\n",
    "title_map = {\n",
    "    'SV': 'SVI',\n",
    "    'EF': 'EF',\n",
    "    'MaxDeriv': 'Max. Derivative',\n",
    "    'MinVolume': 'ESVI',\n",
    "    'MaxVolume': 'EDVI'\n",
    "}\n",
    "\n",
    "metrics = [\n",
    "    {'name': 'SV', 'data': df_sv, 'value_col': 'SV', \n",
    "     'pairwise': df_pw_sv, 'ylabel': 'Stroke Volume (SV)'},\n",
    "    {'name': 'EF', 'data': df_ef, 'value_col': 'EF', \n",
    "     'pairwise': df_pw_ef, 'ylabel': 'Ejection Fraction (EF)'},\n",
    "    {'name': 'MaxDeriv', 'data': df_deriv, 'value_col': 'MaxDeriv', \n",
    "     'pairwise': df_pw_max_deriv, 'ylabel': 'Max |Derivative|'},\n",
    "    {'name': 'MinVolume', 'data': df_min_vol, 'value_col': 'MinVolume', \n",
    "     'pairwise': df_pw_min_vol, 'ylabel': 'Min Volume'},\n",
    "    {'name': 'MaxVolume', 'data': df_max_vol, 'value_col': 'MaxVolume', \n",
    "     'pairwise': df_pw_max_vol, 'ylabel': 'Max Volume'},\n",
    "]\n",
    "\n",
    "\n",
    "# Assume you have your metrics and pairwise test DataFrames (e.g., df_pw_sv, etc.)\n",
    "# Here, we'll show the modified annotation code within the plotting loop:\n",
    "# Set up a grid with 2 rows and 3 columns (total 6 subplots), then only fill 5.\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12), sharey=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, metric in zip(axes, metrics):\n",
    "    data = metric['data']\n",
    "    value_col = metric['value_col']\n",
    "    pairwise_results = metric['pairwise']\n",
    "    ylabel = metric['ylabel']\n",
    "    metric_name = metric['name']\n",
    "    \n",
    "    # Create a boxplot for the metric by segmentation groups with hue for Class.\n",
    "    sns.boxplot(data=data, x='segmentation_type', y=value_col, hue='Class', order=order, \n",
    "                ax=ax, palette=\"Set2\")\n",
    "    # ax.set_title(metric_name, fontsize=14)\n",
    "    metric_title = title_map.get(metric_name, metric_name)\n",
    "    ax.set_title(metric_title)\n",
    "\n",
    "    # ax.set_xlabel('Segmentation', fontsize=12)\n",
    "    ax.set_xlabel('')\n",
    "    # ax.set_ylabel(ylabel, fontsize=12)\n",
    "    ax.set_ylabel('')\n",
    "    \n",
    "    # --- Rename the x-ticks using title_dict ---\n",
    "    # We'll replace e.g. 'gt' -> 'CNN reference', etc.\n",
    "    new_labels = []\n",
    "    for label in ax.get_xticklabels():\n",
    "        txt = label.get_text()  # e.g. 'gt'\n",
    "        new_labels.append(title_dict.get(txt, txt))  # fallback to original if not found\n",
    "    ax.set_xticklabels(new_labels, rotation=0)  # rotation=0 if you want them horizontal\n",
    "\n",
    "    # Determine the hue categories and compute the offset for the box centers.    \n",
    "    # Determine the hue categories and compute the offset for the box centers.\n",
    "    hue_categories = sorted(data['Class'].unique())\n",
    "    n_hue = len(hue_categories)\n",
    "    box_width = 0.8  # default box width in seaborn boxplots\n",
    "\n",
    "    # For each cardiac class (hue), annotate significant differences.\n",
    "    for cl in hue_categories:\n",
    "        class_index = hue_categories.index(cl)\n",
    "        offset = (class_index - (n_hue - 1) / 2) * (box_width / n_hue)\n",
    "        \n",
    "        data_cl = data[data['Class'] == cl]\n",
    "        # Filter the pairwise test results for the current class.\n",
    "        df_pw_cl = pairwise_results[pairwise_results['Class'] == cl]\n",
    "        # Map segmentation groups to their base x-axis positions.\n",
    "        x_coords = {group: order.index(group) for group in order}\n",
    "        \n",
    "        # Use the maximum value for the metric in the current data as baseline for annotations.\n",
    "        y_max_data = data[value_col].max() * 0.9\n",
    "        base_offset = y_max_data * 0.05 if y_max_data != 0 else 0.05\n",
    "        num_annotations = 0\n",
    "        \n",
    "        # Define allowed comparisons (all lowercase, without spaces)\n",
    "        allowed_comparisons = {'gtvspred_base', 'gtvspred_new', 'pred_basevspred_new'}\n",
    "        \n",
    "        for idx, row in df_pw_cl.iterrows():\n",
    "            # Remove spaces and lowercase the comparison string.\n",
    "            comp = row['Comparison'].replace(\" \", \"\").lower()\n",
    "            if comp not in allowed_comparisons:\n",
    "                continue\n",
    "            try:\n",
    "                group1, group2 = comp.split(\"vs\")\n",
    "            except Exception:\n",
    "                continue\n",
    "            if group1 not in x_coords or group2 not in x_coords:\n",
    "                continue\n",
    "            \n",
    "            # Compute x positions in data coordinates (categorical positions are 0,1,2, plus offset)\n",
    "            x1 = x_coords[group1] + offset\n",
    "            x2 = x_coords[group2] + offset\n",
    "\n",
    "            if 'gt' in [group1, group2]:\n",
    "                if group1 == 'gt':\n",
    "                    x_symbol = x2  # put the marker over the second group\n",
    "                else:\n",
    "                    x_symbol = x1  # put the marker over the first group            \n",
    "            else:\n",
    "                # If neither is gt, place symbol at the first one\n",
    "                # x_symbol = (x1 + x2) / 2.0\n",
    "                x_symbol = x1\n",
    "            # mid_x = (x1 + x2) / 2.0\n",
    "            \n",
    "            # Set y for annotation (stack annotations if multiple exist)\n",
    "            y = y_max_data + base_offset * (num_annotations + 0.05)\n",
    "            \n",
    "            p = row['adj_p-value']\n",
    "            if p < 0.05:\n",
    "                # Choose symbol and color based on whether one group is ground truth.\n",
    "                if 'gt' in [group1, group2]:\n",
    "                    symbol = '‚Ä†'      # red dagger for comparisons involving ground truth\n",
    "                    symbol_color = 'red'\n",
    "                else:\n",
    "                    symbol = '‚àó'      # blue asterisk for comparisons between the two approaches\n",
    "                    symbol_color = 'blue'\n",
    "                # Place the symbol in data coordinates.\n",
    "                ax.text(x_symbol, y, symbol, ha='center', va='bottom', \n",
    "                        color=symbol_color, fontsize=16, fontweight='bold')\n",
    "                num_annotations += 1\n",
    "\n",
    "    # Remove the default legend from each subplot\n",
    "    if ax.get_legend() is not None:\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "# Hide the unused subplot if you have only 5 metrics\n",
    "if len(metrics) < len(axes):\n",
    "    for j in range(len(metrics), len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "# Now, use the 6th subplot (axes[5]) for a combined legend.\n",
    "# First, collect the handles and labels from one of the plots.\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "# Create a vertical legend (ncol=1) that covers more of the subplot.\n",
    "axes[5].legend(handles, labels, loc='center', bbox_to_anchor=(0.5, 0.5), ncol=1, \n",
    "               frameon=False, fontsize=20)\n",
    "axes[5].axis('off')  # Hide the axes box for the legend subplot.\n",
    "# Now, collect the handles and labels from the first subplot (or any one that had a legend).\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "\n",
    "# Adjust subplot spacing so there's more room between them\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "save_filename = os.path.join(save_folder_results, 'group_comparisons_sig.png')\n",
    "fig.savefig(save_filename, dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "save_filename = os.path.join(save_folder_results, 'group_comparisons_sig.eps')\n",
    "fig.savefig(save_filename, dpi=300, bbox_inches='tight', pad_inches=0, format='eps')\n",
    "\n",
    "save_filename = os.path.join(save_folder_results, 'group_comparisons_sig.pdf')\n",
    "fig.savefig(save_filename, dpi=300, bbox_inches='tight', pad_inches=0, format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose the variable to analyze (for volume, use 'Volume_Index'; otherwise, use 'Volume')\n",
    "measure = 'Volume_Index'\n",
    "\n",
    "# Compute minimum and maximum volume per subject\n",
    "df_min_vol = df_all_merged.groupby(['Subject', 'segmentation_type', 'Class'])[measure].min().reset_index().rename(columns={measure: 'MinVolume'})\n",
    "df_max_vol = df_all_merged.groupby(['Subject', 'segmentation_type', 'Class'])[measure].max().reset_index().rename(columns={measure: 'MaxVolume'})\n",
    "\n",
    "# Compute EF = (Max - Min) / Max for each subject (merge min and max data)\n",
    "df_ef = pd.merge(df_min_vol, df_max_vol, on=['Subject', 'segmentation_type', 'Class'])\n",
    "df_ef['EF'] = (df_ef['MaxVolume'] - df_ef['MinVolume']) / df_ef['MaxVolume']\n",
    "df_ef['EF'] = df_ef['EF'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# Compute Stroke Volume (SV) as (MaxVolume - MinVolume)\n",
    "# Merge the min and max volume dataframes\n",
    "df_sv = pd.merge(df_min_vol, df_max_vol, on=['Subject', 'segmentation_type', 'Class'])\n",
    "df_sv['SV'] = df_sv['MaxVolume'] - df_sv['MinVolume']\n",
    "\n",
    "# For Derivative measures, assume df_all_merged has a 'Derivative' column.\n",
    "# Compute per-subject min and max derivative for each subject, segmentation, and class.\n",
    "df_deriv = (df_all_merged.groupby(['Subject', 'segmentation_type', 'Class'])['Derivative']\n",
    "                .apply(lambda x: np.abs(x).max())\n",
    "                .reset_index(name='MaxDeriv'))\n",
    "\n",
    "df_ef.groupby(['segmentation_type', 'Class'])[['EF']].agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_vol.groupby(['segmentation_type', 'Class'])[['MaxVolume']].agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min_vol.groupby(['segmentation_type', 'Class'])[['MinVolume']].agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sv.groupby(['segmentation_type', 'Class'])[['SV']].agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deriv.groupby(['segmentation_type', 'Class'])[['MaxDeriv']].agg(['mean', 'std'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimosef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
