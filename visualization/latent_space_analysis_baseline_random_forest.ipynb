{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nimosef.utils.stats import drop_high_nan, process_columns_for_rf\n",
    "from ukb_utils import columns_to_code, columns_to_drop, pretty_name_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/media/jaume/DATA/Data/Urblauna_SFTP/UKB_Cardiac_BIDS'\n",
    "split_filename = 'derivatives/nimosef_flip_logs/train_val_test_split.json'\n",
    "number_patients = 1000\n",
    "\n",
    "# --- Training\n",
    "# baseline\n",
    "# baseline_experiment_name = 'experiment_20250222_221033'\n",
    "# baseline_experiment_name = 'experiment_20250224_185942'\n",
    "# baseline_experiment_name = 'experiment_20250224_190207'\n",
    "# baseline_experiment_name = 'experiment_20250225_161607'\n",
    "\n",
    "# New model\n",
    "# new_model_experiment_name = 'experiment_20250222_214400' # new model\n",
    "# new_model_experiment_name = 'experiment_20250224_190018' # new model\n",
    "# new_model_experiment_name = 'experiment_20250224_190107' # new model\n",
    "# new_model_experiment_name = 'experiment_20250225_161508' # new model\n",
    "\n",
    "# baseline_experiment_name = 'experiment_20250310_175059' # Baseline v1\n",
    "# new_model_experiment_name = 'experiment_20250311_001426' # Motion v1\n",
    "\n",
    "# Mean shape code\n",
    "baseline_experiment_name = 'experiment_20250317_201737'  # Baseline\n",
    "new_model_experiment_name = 'experiment_20250317_201146'  # Motion\n",
    "\n",
    "derivatives_path = os.path.join(data_path, 'derivatives')\n",
    "\n",
    "# For the training\n",
    "dataset_split = 'train'\n",
    "\n",
    "res_factor_z = 1  # Same as original\n",
    "img_folder_baseline = os.path.join(derivatives_path, 'nimosef_flip_logs', 'baseline', f\"imgs_train_{baseline_experiment_name}_res_factor_{res_factor_z}\")\n",
    "img_folder_new_model = os.path.join(derivatives_path, 'nimosef_flip_logs', 'baseline', f\"imgs_train_{new_model_experiment_name}_res_factor_{res_factor_z}\")\n",
    "\n",
    "save_folder_results = os.path.join(derivatives_path, 'nimosef_flip_logs', 'baseline', f\"results_train_comparison_res_factor_{res_factor_z}\")\n",
    "os.makedirs(save_folder_results, exist_ok=True)\n",
    "\n",
    "# Metadata file\n",
    "metadata_filename = os.path.join(derivatives_path, 'metadata_participants_ALL.tsv')\n",
    "\n",
    "save_folder_results = os.path.join(derivatives_path, 'nimosef_flip_logs', 'baseline', f\"results_train_comparison_res_factor_{res_factor_z}\")\n",
    "path_to_baseline_code = os.path.join(derivatives_path, 'nimosef_flip_logs', 'baseline', baseline_experiment_name, 'shape_code.parquet')\n",
    "path_to_new_model_code = os.path.join(derivatives_path, 'nimosef_flip_logs', 'baseline', new_model_experiment_name, 'shape_code.parquet')\n",
    "\n",
    "path_to_baseline_distance = os.path.join(derivatives_path, 'nimosef_flip_logs', 'baseline', baseline_experiment_name, 'shape_code_distances.csv')\n",
    "path_to_new_model_distance = os.path.join(derivatives_path, 'nimosef_flip_logs', 'baseline', new_model_experiment_name, 'shape_code_distances.csv')\n",
    "\n",
    "df_shape_code_baseline = pd.read_parquet(path_to_baseline_code)\n",
    "df_shape_code_new_model = pd.read_parquet(path_to_new_model_code)\n",
    "df_shape_baseline_distance = pd.read_csv(path_to_baseline_distance, index_col=0)\n",
    "df_shape_new_distance = pd.read_csv(path_to_new_model_distance, index_col=0)\n",
    "df_metadata = pd.read_csv(metadata_filename, index_col=0, sep='\\t')\n",
    "\n",
    "# path_to_flip = os.path.join(save_folder_results, 'flip_affine.csv')\n",
    "# df_flip_affine = pd.read_csv(path_to_flip, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_metadata.head())\n",
    "# print(df_shape_new_distance.head())\n",
    "df_shape_baseline_distance.index.name = 'Subject'\n",
    "df_metadata.index.name = 'Subject'\n",
    "# df_flip_affine.index.name = 'Subject'\n",
    "\n",
    "# Merge the metadata and shape distance data on the 'Subject' column\n",
    "df_merged = pd.merge(df_metadata.reset_index().copy(), df_shape_baseline_distance.reset_index().copy(), on='Subject')\n",
    "# df_merged = pd.merge(df_merged, df_flip_affine.reset_index().copy(), on='Subject')\n",
    "# df_merged.head()\n",
    "\n",
    "# Subjects to drop\n",
    "# subj_to_drop = ['sub-1076522', 'sub-1112328', 'sub-1019084', 'sub-1140112', 'sub-1134162']\n",
    "subj_to_drop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assume df_merged is your merged DataFrame.\n",
    "df_merged = pd.merge(df_metadata.reset_index().copy(), df_shape_baseline_distance.reset_index().copy(), on='Subject')\n",
    "# df_merged = pd.merge(df_merged, df_flip_affine.reset_index().copy(), on='Subject')\n",
    "numeric_df = process_columns_for_rf(df_merged.copy(), columns_to_drop, columns_to_code, nan_threshold=1.)\n",
    "\n",
    "# Define the subjects you want to remove\n",
    "numeric_df = numeric_df[~numeric_df[\"Subject\"].isin(subj_to_drop)]\n",
    "numeric_df = numeric_df.reset_index(drop=True)\n",
    "\n",
    "# Optionally, inspect the resulting DataFrame.\n",
    "print(\"Processed DataFrame columns:\")\n",
    "print(numeric_df.columns)\n",
    "print(numeric_df.dtypes)\n",
    "\n",
    "print(numeric_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume your data is already prepared:\n",
    "# y is your target (Distance)\n",
    "# X is obtained via:\n",
    "# X = pd.get_dummies(df_merged.drop(['Subject', 'Distance'], axis=1)).values\n",
    "# Also get the feature names:\n",
    "y = numeric_df['Distance'].values\n",
    "X_df = pd.get_dummies(numeric_df.drop(['Subject', 'Distance'], axis=1))\n",
    "# X_df = numeric_df.drop(['Subject', 'Distance'], axis=1).copy()\n",
    "feature_names = X_df.columns.tolist()\n",
    "X = X_df.values\n",
    "\n",
    "X_sp = pd.get_dummies(numeric_df.drop(['Subject'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "# Define an RMSE scorer (note: many built-in scorers in scikit-learn are \"negative\" for loss functions)\n",
    "rmse_scorer = make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)), greater_is_better=False)\n",
    "# ----------------------------\n",
    "# 5-Fold Cross-Validation Setup\n",
    "# ----------------------------\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluate Prediction Accuracy with Cross-Val Predictions\n",
    "# ----------------------------\n",
    "rf = RandomForestRegressor(n_estimators=501, random_state=42, max_depth=20, max_samples=0.8)\n",
    "\n",
    "# # Get cross-validated predictions for the entire dataset.\n",
    "# y_pred = cross_val_predict(rf, X, y, cv=cv)\n",
    "\n",
    "# # Compute performance metrics.\n",
    "# mae = mean_absolute_error(y, y_pred)\n",
    "# r2 = r2_score(y, y_pred)\n",
    "# print(\"Mean Absolute Error:\", mae)\n",
    "# print(\"R^2 Score:\", r2)\n",
    "\n",
    "# # Scatter plot: True vs Predicted Distance.\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.scatter(y, y_pred, alpha=0.6, edgecolor='k')\n",
    "# plt.plot([min(y), max(y)], [min(y), max(y)], 'r--', lw=2)\n",
    "# plt.xlabel(\"True Distance\")\n",
    "# plt.ylabel(\"Predicted Distance\")\n",
    "# plt.title(\"True vs Predicted Distance\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Histogram of Residuals.\n",
    "# errors = y_pred - y\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# sns.histplot(errors, bins=30, kde=True)\n",
    "# plt.xlabel(\"Prediction Error (Predicted - True)\")\n",
    "# plt.title(\"Distribution of Prediction Errors\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# Compute and Visualize Feature Importances via CV\n",
    "# ----------------------------\n",
    "all_importances = []\n",
    "fold_maes = []\n",
    "fold_r2s = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    # Train a new model on each fold.\n",
    "    rf_fold = RandomForestRegressor(n_estimators=501, random_state=42, max_depth=20, max_samples=0.8)\n",
    "    rf_fold.fit(X_train, y_train)\n",
    "    all_importances.append(rf_fold.feature_importances_)\n",
    "    \n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    y_pred_fold = rf_fold.predict(X_test)    \n",
    "    fold_maes.append(mean_absolute_error(y_test, y_pred_fold))\n",
    "    fold_r2s.append(r2_score(y_test, y_pred_fold))\n",
    "\n",
    "print(\"MAE for each fold:\", fold_maes)\n",
    "print(\"Mean MAE:\", np.mean(fold_maes))\n",
    "print(\"R² for each fold:\", fold_r2s)\n",
    "print(\"Mean R²:\", np.mean(fold_r2s))\n",
    "\n",
    "all_importances = np.array(all_importances)  # shape: (n_folds, n_features)\n",
    "mean_importances = np.mean(all_importances, axis=0)\n",
    "\n",
    "# Sort features by importance.\n",
    "sorted_indices = np.argsort(mean_importances)[::-1]\n",
    "top_n = 10  # Number of top features to display.\n",
    "top_features = [feature_names[i] for i in sorted_indices[:top_n]]\n",
    "top_importances = mean_importances[sorted_indices][:top_n]\n",
    "\n",
    "# Plot feature importances.\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_importances, y=top_features, palette=\"viridis\")\n",
    "plt.xlabel(\"Average Feature Importance\")\n",
    "plt.title(f\"Top {top_n} Important Features (5-Fold CV)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance = pd.DataFrame(data=all_importances, columns=feature_names, index=[f\"Fold_{i}\" for i in range(1, 6)])\n",
    "df_mae = pd.DataFrame(data=fold_maes, columns=['MAE'], index=[f\"Fold_{i}\" for i in range(1, 6)])\n",
    "df_r2 = pd.DataFrame(data=fold_r2s, columns=['R²'], index=[f\"Fold_{i}\" for i in range(1, 6)])\n",
    "df_scores = pd.concat([df_mae, df_r2], axis=1)\n",
    "\n",
    "df_scores.to_csv(os.path.join(save_folder_results, 'scores_baseline.csv'))\n",
    "df_importance.to_csv(os.path.join(save_folder_results, 'importance_baseline.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_3d_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
